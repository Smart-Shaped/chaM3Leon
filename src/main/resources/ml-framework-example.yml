ml:
  spark:
    app:
      name: "ml-application"
    master: "yarn"
    submit:
      deployMode: "cluster"
    yarn:
      am:
        cores: 1
        memory: "512m"
        memoryOverhead: "384m"
    driver:
      memory: "512m"
      memoryOverhead: "384m"
      cores: 1
      maxResultSize: "1g"
    executor:
      memoryOverhead: "384m"
      memory: "512m"
      instances: 2
      cores: 1
    serializer: "org.apache.spark.serializer.KryoSerializer"
    memory:
      fraction: 0.7
      storageFraction: 0.5
      offHeap:
        enabled: true
        size: "1g"
    sql:
      parquet:
        compression:
          codec: "zstd"
      shuffle:
        partitions: 200
    hadoop:
      parquet:
        page:
          size:
            row:
              check:
                min: 2
                max: 10
      dfs:
        replication: 1
  hdfs:
    filter:
      polygon: ""
    manipulation:
      splittingFactorX: "0"
      splittingFactorY: "0"
      rescalingFactorX: "0"
      rescalingFactorY: "0"
    readers:
      default: ""
      reader1:
        class: "com.smartshaped.fesr.ml.GeoTiffReader"
        path: "/tif"
      reader2:
        class: "com.smartshaped.fesr.ml.NASACsvReader"
        path: "/csv"
